# LiDAR-Camera Data Fusion System

ROS 환경에서 Yujin LiDAR와 웹캠을 이용한 센서 융합 및 데이터 처리 시스템입니다.

## 프로젝트 개요

이 프로젝트는 LiDAR 포인트 클라우드 데이터와 카메라 이미지를 동기화하여 3D 공간 정보를 2D 이미지에 투영하는 센서 융합 시스템입니다. ROS를 통해 실시간으로 데이터를 수집하고, 캘리브레이션을 통해 정확한 좌표 변환을 수행합니다.

## 시스템 구성

### 하드웨어
- Yujin LiDAR 센서
- USB 웹캠
- ROS 지원 컴퓨팅 플랫폼

### 소프트웨어 스택
- ROS (Robot Operating System)
- OpenCV (컴퓨터 비전)
- Open3D (3D 포인트 클라우드 처리)
- NumPy (수치 계산)

## 주요 기능

### 1. 데이터 수집 (ros_pcd_pic_save.py)
ROS 토픽을 통해 LiDAR 포인트 클라우드와 웹캠 이미지를 동시에 수집합니다.
- LiDAR 데이터: /yrl_pub/yrl_cloud 토픽 구독
- 이미지 데이터: OpenCV를 통한 웹캠 캡처
- 시간 동기화된 데이터셋 생성

### 2. 카메라 캘리브레이션 (camera_calibration.py)
체커보드 패턴을 이용한 카메라 내부 파라미터 추출
- 카메라 매트릭스 (fx, fy, cx, cy) 계산
- 왜곡 계수 추정
- YAML 형식으로 캘리브레이션 결과 저장

### 3. 이미지 왜곡 보정 (calied_image.py)
캘리브레이션 결과를 바탕으로 원본 이미지의 렌즈 왜곡을 제거합니다.
- 배럴/핀쿠션 왜곡 보정
- 최적화된 카메라 매트릭스 적용
- ROI 영역 자동 크롭

### 4. 포인트 클라우드 전처리 (pcd_preprocessing.py)
노이즈 제거 및 데이터 최적화
- Voxel 다운샘플링으로 데이터 밀도 조절
- Statistical Outlier Removal을 통한 노이즈 제거
- 처리된 PCD 파일 생성

### 5. 센서 융합 및 투영 (sync.py)
LiDAR 3D 포인트를 카메라 이미지 평면에 투영하는 핵심 모듈입니다.

#### 좌표 변환 과정
LiDAR 좌표계 → 카메라 좌표계 → 이미지 좌표계


#### 외부 파라미터 설정
회전 행렬 R과 변환 벡터 T를 통해 LiDAR와 카메라 간의 상대적 위치 관계를 정의합니다.
- R: LiDAR 좌표계를 카메라 좌표계로 회전
- T: 두 센서 간의 평행 이동량

#### 투영 변환
1. 동차좌표 변환: 3D 포인트를 4D 동차좌표로 확장
2. 외부 파라미터 적용: [R|T] 매트릭스를 통한 좌표계 변환
3. 카메라 투영: 내부 파라미터(K)를 사용한 핀홀 카메라 모델 적용
4. 정규화: Z값으로 나누어 2D 이미지 좌표 획득

#### 깊이 시각화
거리 정보를 컬러맵으로 표현하여 직관적인 3D 정보 제공
- Z값 정규화 (0-255 범위)
- JET 컬러맵 적용
- 거리별 색상 구분 (파란색: 가까움, 빨간색: 멀음)

#### 출력 결과
- 원본 이미지에 LiDAR 포인트 오버레이
- 검은 배경에 LiDAR 포인트만 표시한 깊이 맵
- 픽셀별 거리 정보가 색상으로 인코딩된 결과

